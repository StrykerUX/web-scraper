# Plan de Pruebas - Web Scraper con Playwright

## üìã Descripci√≥n General

Este documento establece el plan de pruebas para el script de recolecci√≥n de datos web (`scraper.js`), que implementa la **Fase 1 del pipeline** descrito en el documento de referencia.

**Objetivo:** Validar que el scraper recolecta correctamente:
- HTML final renderizado (desktop y mobile)
- Screenshots en m√∫ltiples viewports
- Lista de clases CSS
- Metadata de la p√°gina (im√°genes, links, formularios, headings)
- Detecci√≥n autom√°tica de tecnolog√≠as

**Versi√≥n del Plan:** 1.0
**Fecha de Creaci√≥n:** 2025-10-21
**Herramientas:** Playwright v1.56.1

---

## üéØ Objetivos de Prueba

1. ‚úÖ Verificar que el scraper se conecte exitosamente a URLs v√°lidas
2. ‚úÖ Validar que el HTML final se capture correctamente (con contenido din√°mico)
3. ‚úÖ Confirmar que los screenshots se generen en ambos viewports (desktop 1920x1080 y mobile 375x667)
4. ‚úÖ Verificar que se extraigan todas las clases CSS utilizadas
5. ‚úÖ Validar la detecci√≥n autom√°tica de frameworks y librer√≠as
6. ‚úÖ Confirmar que los archivos de salida se generen en la estructura correcta
7. ‚úÖ Validar manejo de errores para URLs inv√°lidas o sitios bloqueados
8. ‚úÖ Verificar el c√°lculo del score de confianza

---

## üß™ Casos de Prueba

### **TC-001: Scraping B√°sico de Sitio Est√°tico**

**Descripci√≥n:** Validar que el scraper funcione con un sitio web est√°tico simple.

**Precondiciones:**
- Playwright est√° instalado y los navegadores est√°n disponibles
- Conexi√≥n a internet activa
- URL v√°lida de un sitio est√°tico (ej: ejemplo.com)

**Pasos:**
1. Ejecutar: `npm run scrape https://example.com`
2. Esperar a que se complete el proceso
3. Verificar que se creer la carpeta `output/[timestamp]/`
4. Confirmar que se generan los siguientes archivos:
   - `data.json`
   - `summary.json`
   - `classes.json`
   - `page-desktop.html`
   - `page-mobile.html`
   - `screenshot-desktop.png`
   - `screenshot-mobile.png`

**Criterios de Aceptaci√≥n:**
- [ ] Todos los archivos se generan sin errores
- [ ] Los HTMLs contienen m√°s de 100 caracteres
- [ ] Las im√°genes PNG tienen tama√±o > 0
- [ ] `data.json` es v√°lido y contiene estructura esperada
- [ ] La duraci√≥n total < 60 segundos

**Resultado Esperado:**
```
‚úì Directorio creado: output/[timestamp]
‚úì Screenshot desktop guardado
‚úì Screenshot mobile guardado
‚úì Datos guardados en: data.json
‚úì Resumen guardado: summary.json
‚úÖ Scraping completado exitosamente
```

---

### **TC-002: Extracci√≥n de Clases CSS**

**Descripci√≥n:** Validar que todas las clases CSS se extraigan correctamente.

**Precondiciones:**
- Completado TC-001
- Acceso al archivo `classes.json` generado

**Pasos:**
1. Abrir `output/[timestamp]/classes.json`
2. Verificar el campo `total`
3. Inspeccionar el array `classes`
4. Validar contra el HTML guardado manualmente:
   ```bash
   grep -o 'class="[^"]*"' page-desktop.html | wc -l
   ```

**Criterios de Aceptaci√≥n:**
- [ ] `total` > 0 (m√≠nimo 1 clase detectada)
- [ ] Todas las clases son strings v√°lidos
- [ ] No hay clases vac√≠as o duplicadas
- [ ] Clases coinciden con las del HTML

**Validaci√≥n de Contenido:**
```json
{
  "total": 45,
  "classes": [
    "container",
    "d-flex",
    "justify-content-center",
    ...
  ]
}
```

---

### **TC-003: Detecci√≥n de Tecnolog√≠as**

**Descripci√≥n:** Validar que se detecten correctamente frameworks y librer√≠as.

**Precondiciones:**
- Sitio objetivo usa tecnolog√≠as conocidas (React, Next.js, Tailwind, Bootstrap)
- Completado TC-001

**Pasos:**
1. Ejecutar scraper en un sitio con Next.js y Tailwind (ej: vercel.com, nextjs.org)
2. Abrir `output/[timestamp]/summary.json`
3. Verificar el campo `technologies`

**Criterios de Aceptaci√≥n:**
- [ ] Campo `technologies` existe en metadata
- [ ] Contiene al menos 1 framework o librer√≠a detectado
- [ ] Los valores son strings v√°lidos en min√∫sculas
- [ ] Coinciden con lo que se ve en el c√≥digo fuente

**Validaci√≥n de Contenido:**
```json
{
  "technologies": {
    "frameworks": ["next.js", "react"],
    "cssFrameworks": ["tailwind"],
    "libraries": []
  }
}
```

---

### **TC-004: Extracci√≥n de Elementos HTML**

**Descripci√≥n:** Validar que se extraigan correctamente im√°genes, links, formularios y headings.

**Precondiciones:**
- Completado TC-001
- Sitio objetivo contiene estos elementos

**Pasos:**
1. Abrir `output/[timestamp]/data.json`
2. Verificar secciones: `images`, `links`, `forms`, `headings`
3. Contar elementos en el HTML manualmente:
   ```bash
   grep -c "<img" page-desktop.html
   grep -c "<a href" page-desktop.html
   grep -c "<form" page-desktop.html
   grep -c "<h[1-6]" page-desktop.html
   ```

**Criterios de Aceptaci√≥n:**
- [ ] `images` contiene objetos con campos: `src`, `alt`, `width`, `height`
- [ ] `links` (m√°ximo 50) contiene: `href`, `text`
- [ ] `forms` contiene: `id`, `name`, `action`, `method`, `inputs`
- [ ] `headings` contiene: `level`, `text`
- [ ] Cantidades son realistas (no vac√≠as para sitios normales)

---

### **TC-005: Screenshots en Diferentes Viewports**

**Descripci√≥n:** Validar que se generen screenshots correctamente en ambos viewports.

**Precondiciones:**
- Completado TC-001
- Archivos de screenshot generados

**Pasos:**
1. Abrir `output/[timestamp]/screenshot-desktop.png`
2. Abrir `output/[timestamp]/screenshot-mobile.png`
3. Verificar visualmente:
   - Desktop: ancho correcto (~1920px)
   - Mobile: ancho correcto (~375px)
4. Usar herramienta para verificar dimensiones:
   ```bash
   file screenshot-desktop.png
   file screenshot-mobile.png
   ```

**Criterios de Aceptaci√≥n:**
- [ ] Ambas im√°genes se cargan sin corrupci√≥n
- [ ] Desktop es m√°s ancho que mobile (visible)
- [ ] Contenido es legible en ambas
- [ ] Tama√±o de archivo desktop > mobile

**Validaci√≥n Visual:**
- Screenshots deben mostrar el contenido real del sitio, no errores

---

### **TC-006: HTML Final vs HTML Original**

**Descripci√≥n:** Validar que el HTML capturado es el versi√≥n final (con contenido din√°mico).

**Precondiciones:**
- Completado TC-001
- Acceso al sitio original en navegador

**Pasos:**
1. Abrir el sitio original en navegador
2. Guardar HTML con `Ctrl+S` o DevTools ‚Üí `Save as HTML`
3. Comparar con `page-desktop.html` generado
4. Buscar contenido din√°mico espec√≠fico:
   ```bash
   # Buscar elementos que solo aparecen despu√©s de JavaScript
   grep "dinamico" page-desktop.html
   ```

**Criterios de Aceptaci√≥n:**
- [ ] HTML capturado contiene contenido renderizado (no templates vac√≠os)
- [ ] Incluye datos que requieren JavaScript
- [ ] No contiene `<script>` sin ejecutar

---

### **TC-007: C√°lculo de Confidence Score**

**Descripci√≥n:** Validar que el score de confianza se calcule correctamente.

**Precondiciones:**
- Completado TC-001
- Acceso a `summary.json`

**Pasos:**
1. Abrir `summary.json`
2. Revisar el campo `confidence`
3. Revisar `statistics`
4. Validar c√°lculo:
   ```
   Score base: 100
   - Si classes < 10: -20 puntos
   - Si images = 0: -10 puntos
   - Si forms = 0: -5 puntos
   + Si headings > 5: +10 puntos
   + Si links > 10: +10 puntos
   Rango final: 0-100
   ```

**Criterios de Aceptaci√≥n:**
- [ ] Confidence es n√∫mero entre 0-100
- [ ] Coincide con la f√≥rmula de c√°lculo
- [ ] Sitios con mucho contenido: confidence > 80
- [ ] Sitios con poco contenido: confidence 50-80

---

### **TC-008: Manejo de Errores - URL Inv√°lida**

**Descripci√≥n:** Validar que el scraper maneja correctamente URLs inv√°lidas.

**Precondiciones:**
- Playwright instalado

**Pasos:**
1. Ejecutar: `npm run scrape "esto-no-es-una-url"`
2. Observar el mensaje de error

**Criterios de Aceptaci√≥n:**
- [ ] Script muestra error claro: "URL inv√°lida"
- [ ] No crea carpeta de output
- [ ] Exit code es 1
- [ ] Mensaje es informativo

**Resultado Esperado:**
```
‚ùå URL inv√°lida: esto-no-es-una-url
```

---

### **TC-009: Manejo de Errores - URL No Accesible**

**Descripci√≥n:** Validar que el scraper maneja URLs que no responden.

**Precondiciones:**
- URL que definitivamente no existe (ej: https://definitivamente-no-existe-12345.com)

**Pasos:**
1. Ejecutar: `npm run scrape https://definitivamente-no-existe-12345.com`
2. Esperar respuesta

**Criterios de Aceptaci√≥n:**
- [ ] Script muestra error descriptivo
- [ ] Menciona timeout o conexi√≥n fallida
- [ ] No crea archivos corruptos
- [ ] Exit code es 1

**Resultado Esperado:**
```
‚ùå Error durante el scraping: [timeout/connection error message]
```

---

### **TC-010: Sin Argumentos**

**Descripci√≥n:** Validar comportamiento cuando no se proporciona URL.

**Precondiciones:**
- Script disponible

**Pasos:**
1. Ejecutar: `npm run scrape`
2. Sin argumentos

**Criterios de Aceptaci√≥n:**
- [ ] Muestra instrucciones de uso
- [ ] Ejemplo incluido
- [ ] Exit code es 1

**Resultado Esperado:**
```
‚ùå Uso: node scraper.js <URL>
Ejemplo: node scraper.js https://example.com
```

---

### **TC-011: M√∫ltiples Ejecuciones Simult√°neas**

**Descripci√≥n:** Validar que m√∫ltiples instancias no causen conflictos.

**Precondiciones:**
- 2+ URLs disponibles
- Suficientes recursos

**Pasos:**
1. Ejecutar en terminal 1: `npm run scrape https://example.com &`
2. Ejecutar en terminal 2: `npm run scrape https://google.com &`
3. Esperar a que ambas terminen
4. Verificar archivos en `output/`

**Criterios de Aceptaci√≥n:**
- [ ] Ambas ejecuciones completadas sin error
- [ ] Carpetas separadas en `output/` (timestamps diferentes)
- [ ] No hay corrupci√≥n de archivos

---

### **TC-012: Estructura de Carpetas y Archivos**

**Descripci√≥n:** Validar que la estructura de salida sea consistente.

**Precondiciones:**
- Completado TC-001

**Pasos:**
1. Ejecutar: `tree output/` o `ls -la output/[timestamp]/`
2. Verificar estructura

**Criterios de Aceptaci√≥n:**
- [ ] Carpeta timestamp tiene formato correcto: `YYYY-MM-DDTHH-MM-SS-mmm`
- [ ] Contiene exactamente 7 archivos
- [ ] Todos los archivos nombrados correctamente
- [ ] No hay archivos extras

**Estructura Esperada:**
```
output/
‚îî‚îÄ‚îÄ 2025-10-21T14-30-45-123/
    ‚îú‚îÄ‚îÄ data.json
    ‚îú‚îÄ‚îÄ summary.json
    ‚îú‚îÄ‚îÄ classes.json
    ‚îú‚îÄ‚îÄ page-desktop.html
    ‚îú‚îÄ‚îÄ page-mobile.html
    ‚îú‚îÄ‚îÄ screenshot-desktop.png
    ‚îî‚îÄ‚îÄ screenshot-mobile.png
```

---

## üìä Checklist de Ejecuci√≥n

Antes de considerar el scraper como "listo para producci√≥n", completar:

### Pruebas Funcionales
- [ ] TC-001: Scraping b√°sico
- [ ] TC-002: Extracci√≥n de clases CSS
- [ ] TC-003: Detecci√≥n de tecnolog√≠as
- [ ] TC-004: Extracci√≥n de elementos HTML
- [ ] TC-005: Screenshots en viewports
- [ ] TC-006: HTML final vs original
- [ ] TC-007: C√°lculo de confidence
- [ ] TC-008: URL inv√°lida
- [ ] TC-009: URL no accesible
- [ ] TC-010: Sin argumentos
- [ ] TC-011: M√∫ltiples ejecuciones
- [ ] TC-012: Estructura de archivos

### Pruebas de Rendimiento
- [ ] Scraping < 60 segundos (sitio t√≠pico)
- [ ] Uso de memoria < 500MB
- [ ] Navegadores se cierran correctamente

### Validaci√≥n de C√≥digo
- [ ] No hay console.log() de debug (solo console.log con emojis informativos)
- [ ] Manejo de errores en todos los await
- [ ] Variables nombradas claramente
- [ ] Comentarios en funciones principales

### Documentaci√≥n
- [ ] README.md con instrucciones
- [ ] Ejemplos de salida incluidos
- [ ] Comentarios en el c√≥digo

---

## üß™ Matriz de Pruebas por Tipo de Sitio

| Tipo de Sitio | TC Aplicables | Notas |
|---|---|---|
| Sitio Est√°tico HTML | TC-001, TC-002, TC-005, TC-012 | M√°s simple, todo renderizado server-side |
| SPA (React/Vue) | TC-001, TC-003, TC-004, TC-006 | Requiere wait networkidle |
| E-commerce | TC-001, TC-004, TC-005 | Suele tener muchos formularios y im√°genes |
| Blog/News | TC-001, TC-002, TC-004 | Muchos headings y links |
| API/Dashboard | TC-008, TC-009 | Posibles requerimientos de auth |

---

## üöÄ Criterios de Aceptaci√≥n Global

El scraper est√° **LISTO** cuando:

‚úÖ **M√≠nimo 11 de 12 TCs pasadas**
‚úÖ **Todas las pruebas de error (TC-008, TC-009, TC-010) pasadas**
‚úÖ **Estructura de salida consistente**
‚úÖ **Rendimiento < 60 segundos**
‚úÖ **Documentaci√≥n completa**

---

## üìù Notas de Implementaci√≥n

### Observaciones Importantes
1. **Wappalyzer Deprecado:** El paquete est√° deprecado. Alternativas: implementar detecci√≥n manual o usar librer√≠a alternativa en futuro
2. **Dependencias del Sistema:** En Linux necesita `libasound2t64` - ya mostrado en instalaci√≥n
3. **Timeout:** Configurado a 30 segundos por defecto, ajustar si sitios son lentos
4. **User-Agent:** Configurado para evitar bloqueos anti-bot b√°sicos

### Limitaciones Conocidas
- No maneja sitios que requieren autenticaci√≥n (auth ser√° feature futura)
- Clases CSS limitadas a DOM visible (no CSS-in-JS runtime)
- Max 50 links extra√≠dos para evitar saturaci√≥n
- No detecta versiones espec√≠ficas de librer√≠as (solo si est√°n presentes)

---

## üîÑ Pr√≥ximas Fases

Este plan cubre **Fase 1: Recolecci√≥n Fiel de Datos**

Fases futuras:
- **Fase 2:** Generaci√≥n del c√≥digo (Prompt a Claude Code)
- **Fase 3:** Control de calidad autom√°tico (QA Tests, Linters)

---

## üìû Contacto y Soporte

Si un test falla:
1. Revisar logs completos del script
2. Verificar conexi√≥n a internet
3. Confirmar que URL es v√°lida y accesible
4. Revisar estructura esperada en este documento

---

**Versi√≥n:** 1.0
**√öltima Actualizaci√≥n:** 2025-10-21
**Estado:** ‚úÖ Activo y Validado
