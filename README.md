# Web Scraper con Playwright - Fase 1

Herramienta de recolecciÃ³n automÃ¡tica de datos web para extraer HTML, screenshots, CSS y metadata de sitios.

## ğŸš€ InstalaciÃ³n

Ya completada. Los archivos necesarios estÃ¡n en su lugar.

### Verificar InstalaciÃ³n
```bash
npm --version      # Node.js debe estar instalado
npx playwright --version  # Debe mostrar v1.56.1 o similar
```

## ğŸ“– Uso RÃ¡pido

### Ejecutar Scraper
```bash
npm run scrape https://example.com
```

### Ejemplos de URLs para Probar
```bash
# Sitio estÃ¡tico simple
npm run scrape https://example.com

# Sitio con React/Next.js
npm run scrape https://nextjs.org

# Blog/News
npm run scrape https://github.com

# E-commerce
npm run scrape https://www.amazon.com
```

## ğŸ“ Estructura del Proyecto

```
play/
â”œâ”€â”€ scraper.js                 # Script principal de scraping
â”œâ”€â”€ package.json               # Dependencias y scripts
â”œâ”€â”€ package-lock.json          # Lock de versiones
â”œâ”€â”€ PLAN_DE_PRUEBAS.md        # Plan completo de testing
â”œâ”€â”€ README.md                  # Este archivo
â””â”€â”€ output/                    # Carpeta de resultados (se crea automÃ¡ticamente)
    â””â”€â”€ 2025-10-21T14-30-45-123/  # Timestamp de ejecuciÃ³n
        â”œâ”€â”€ data.json          # Todos los datos extraÃ­dos (JSON)
        â”œâ”€â”€ summary.json       # Resumen y metadatos
        â”œâ”€â”€ classes.json       # Lista de clases CSS
        â”œâ”€â”€ page-desktop.html  # HTML completo (versiÃ³n desktop)
        â”œâ”€â”€ page-mobile.html   # HTML completo (versiÃ³n mobile)
        â”œâ”€â”€ screenshot-desktop.png  # Captura 1920x1080
        â””â”€â”€ screenshot-mobile.png   # Captura 375x667
```

## ğŸ“Š Salida del Scraper

### archivo `summary.json` (Resumen RÃ¡pido)
```json
{
  "url": "https://example.com",
  "scrapedAt": "2025-10-21T14:30:45.123Z",
  "technologies": {
    "frameworks": ["react"],
    "cssFrameworks": ["tailwind"],
    "libraries": []
  },
  "confidence": 92,
  "statistics": {
    "totalClasses": 156,
    "totalImages": 23,
    "totalLinks": 45,
    "totalForms": 2,
    "totalHeadings": 8
  },
  "files": { ... }
}
```

### archivo `data.json` (Datos Completos)
Contiene:
- **html.desktop** / **html.mobile** - HTML completo renderizado
- **css.classes** - Array de todas las clases CSS
- **images** - Lista de imÃ¡genes con src, alt, dimensiones
- **links** - Lista de enlaces (mÃ¡x 50)
- **forms** - Estructura de formularios
- **headings** - TÃ­tulos/encabezados
- **metadata** - URL, timestamp, tecnologÃ­as detectadas
- **confidence** - Score 0-100 de quÃ© tan completo es el scrape

### archivo `classes.json`
```json
{
  "total": 156,
  "classes": [
    "container",
    "flex",
    "justify-center",
    "text-lg",
    "bg-slate-900",
    ...
  ]
}
```

## ğŸ§ª Pruebas

Ver documento completo: [`PLAN_DE_PRUEBAS.md`](./PLAN_DE_PRUEBAS.md)

### Test RÃ¡pido
```bash
# Probar con example.com (sitio simple)
npm run scrape https://example.com

# Verificar que se creÃ³ la carpeta output/
ls -la output/

# Ver el resumen
cat output/*/summary.json | jq .
```

### Validar Salida
```bash
# Contar clases CSS extraÃ­das
jq '.css.classes | length' output/*/data.json

# Ver tecnologÃ­as detectadas
jq '.metadata.technologies' output/*/data.json

# Listar archivos generados
ls -lh output/*/
```

## âš™ï¸ ConfiguraciÃ³n

### Viewport Predeterminado
- **Desktop:** 1920x1080 (usuario con monitor grande)
- **Mobile:** 375x667 (iPhone SE)

Para cambiar, editar `scraper.js` lÃ­neas ~140 y ~170.

### Timeout
Predeterminado: **30 segundos** por pÃ¡gina

Para sitios lentos, cambiar en `scraper.js` lÃ­nea ~165:
```javascript
// Cambiar de:
timeout: 30000,
// A:
timeout: 60000, // 60 segundos
```

### User-Agent
Por defecto emula navegadores reales para evitar bloqueos.

Editar en `scraper.js` lÃ­neas ~142 (desktop) y ~172 (mobile).

## ğŸ” DetecciÃ³n de TecnologÃ­as

El script detecta automÃ¡ticamente:
- **Frameworks:** React, Vue, Angular, Svelte, Next.js, Nuxt
- **CSS:** Tailwind, Bootstrap
- **MÃ©todo:** Analiza URLs de scripts y contenido HTML

Para ampliar detecciones, editar funciÃ³n `detectTechnologies()` en `scraper.js`.

## âŒ SoluciÃ³n de Problemas

### Error: "Playwright not installed"
```bash
npm install
npx playwright install
```

### Error: "Browser launch failed"
**En Linux**, instalar dependencias:
```bash
npx playwright install-deps
# O manualmente:
sudo apt-get install libasound2t64
```

### Error: "Timeout waiting for..."
- Sitio es muy lento (aumentar timeout)
- Requiere autenticaciÃ³n (no soportado aÃºn)
- URL bloqueada (usa anti-bot)

**SoluciÃ³n:** Aumentar timeout en configuraciÃ³n o usar URL diferente.

### Error: "Invalid URL"
```bash
# Incorrecto:
npm run scrape example.com

# Correcto:
npm run scrape https://example.com
npm run scrape http://example.com
```

### La carpeta `output/` estÃ¡ vacÃ­a
Revisar si hubo errores en los logs. El script imprime mensajes detallados.

## ğŸ“ˆ Siguientes Pasos (Fase 2 y 3)

Una vez tengas los datos extraÃ­dos en `data.json`:

1. **Fase 2:** Pasar los datos a Claude Code para generar cÃ³digo
   - Usar el JSON como entrada al prompt
   - Especificar framework destino (Next.js, React, etc.)

2. **Fase 3:** QA automÃ¡tico
   - Comparar screenshots original vs generado
   - Validar CSS con linters
   - Ejecutar tests

## ğŸ“ Notas Importantes

- âš ï¸ **Respeto Legal:** No usar para copiar contenido protegido sin permiso
- âš ï¸ **Anti-bot:** Algunos sitios bloquean scrapers. Respetar `robots.txt`
- âš ï¸ **Rate Limiting:** No hacer cientos de requests simultÃ¡neos
- â„¹ï¸ **Confidencialidad:** Los datos se guardan localmente en `output/`

## ğŸ› ï¸ PersonalizaciÃ³n

### Agregar MÃ¡s Metadatos
Editar `extractPageInfo()` en `scraper.js` para extraer:
- Meta tags
- Open Graph (og:)
- JSON-LD structured data
- CSS custom properties (variables)

### Cambiar Formato de Salida
Por defecto: JSON. Posibles extensiones:
- CSV (para clases CSS)
- ZIP (comprimir todo)
- Base64 (para pasar a Claude)

## ğŸ’¡ Tips

1. **Verificar salida HTML:**
   ```bash
   file output/*/page-desktop.html
   wc -l output/*/page-desktop.html
   ```

2. **Ver clases CSS Ãºnicas:**
   ```bash
   jq '.css.classes[:20]' output/*/data.json  # Primeras 20
   ```

3. **Contar elementos:**
   ```bash
   jq '.images | length' output/*/data.json
   jq '.links | length' output/*/data.json
   ```

4. **Verificar confidence:**
   ```bash
   jq '.confidence' output/*/summary.json
   ```

## ğŸ“š Referencias

- [Playwright Documentation](https://playwright.dev)
- [Plan de Pruebas Completo](./PLAN_DE_PRUEBAS.md)
- [Documento de Propuesta Original](../Sugerencia%20de%20herramientas%20extra.pdf)

## ğŸ“ Soporte

Si algo no funciona:
1. Revisar [`PLAN_DE_PRUEBAS.md`](./PLAN_DE_PRUEBAS.md) para tu caso de uso
2. Ejecutar con una URL conocida (example.com)
3. Revisar los logs completos en consola
4. Verificar conectividad a internet

---

**VersiÃ³n:** 1.0
**Creado:** 2025-10-21
**Estado:** âœ… Listo para usar
